{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7M6g-P1ZtSi"
   },
   "source": [
    "# Using the OpenVINOâ„¢ Execution Provider for YOLOv8 Detection\n",
    "\n",
    "[Source (modified from Microsoft ONNX Runtime OpenVINO EP Examples)](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/python/OpenVINO_EP/yolov8_object_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UPwBfDzCWmVX",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.2.81)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.2.2+cpu)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.17.2+cpu)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.0.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\riach\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "5BqlWQzFbhf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other images options : https://storage.openvinotoolkit.org/data/test_data/images/cat.jpg, https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\n"
     ]
    }
   ],
   "source": [
    "#Defining a sample image for inference\n",
    "image_url = \"https://ultralytics.com/images/bus.jpg\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYwIEFWpkFqz"
   },
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XmHT7vWLkKFy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import torch\n",
    "from statistics import mean\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data.augment import LetterBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W5B11Gp5aZKz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ultralytics.com/images/bus.jpg\n",
      "Image sucessfully downloaded:  C:\\Users\\riach\\Downloads\n"
     ]
    }
   ],
   "source": [
    "# Parameters for pre-processing\n",
    "imgsz = (640,640) # default value for this usecase.\n",
    "stride = 32 # default value for this usecase( differs based on the model selected\n",
    "\n",
    "print(image_url)\n",
    "def preprocess(image_url):\n",
    "    ## Set up the image URL\n",
    "    path = os.getcwd()\n",
    "    image_path=os.path.join(path, image_url.split(\"/\")[-1])\n",
    "    # Open the url image, set stream to True, this will return the stream content.\n",
    "    r = requests.get(image_url, stream = True)\n",
    "    # Check if the image was retrieved successfully\n",
    "    if r.status_code == 200:\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        r.raw.decode_content = True\n",
    "        # Open a local file with wb ( write binary ) permission.\n",
    "        with open(image_path,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "        print('Image sucessfully downloaded: ',path)\n",
    "    else:\n",
    "        print('Image couldn\\'t be retreived')\n",
    "        return\n",
    "    image_abs_path = os.path.abspath(image_path)\n",
    "    if os.path.isfile(image_abs_path) and image_abs_path.split('.')[-1].lower() in ['jpg', 'jpeg', 'png']:\n",
    "        # Load Image\n",
    "        img0 = cv2.imread(image_abs_path)\n",
    "        # Padded resize\n",
    "        #Letterbox: Resize image and padding for detection, instance segmentation, pose\n",
    "        img = LetterBox(imgsz, stride=stride)(image=img0.copy())\n",
    "        # Convert\n",
    "        img =  img.transpose((2, 0, 1))[::-1]  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = img.astype(np.float32)  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndim == 3:\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "        return img0, img\n",
    "    else:\n",
    "        print(\"Invalid image format.\")\n",
    "        return\n",
    "\n",
    "org_input, model_input = preprocess(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LOTNlHfhjQT"
   },
   "source": [
    "## Downloading a YOLOv8 Model and Exporting it to Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0vAlvihChxnv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.81  Python-3.11.9 torch-2.2.2+cpu CPU (Intel Core(TM) Ultra 9 185H)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (2.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\riach\\Downloads\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolov8n.onnx for ONNX Runtime inference...\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\riach\\Downloads\\bus.jpg: 640x640 4 persons, 1 bus, 63.1ms\n",
      "Speed: 0.0ms preprocess, 63.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format=\"onnx\")  # creates 'yolov8n.onnx'\n",
    "\n",
    "# Load the exported ONNX model\n",
    "onnx_model = YOLO(\"yolov8n.onnx\")\n",
    "\n",
    "# Run inference\n",
    "results = onnx_model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btKE6yeDgj4T"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WrPPbh0Qgnt-"
   },
   "outputs": [],
   "source": [
    "original_model_path = \"/content/model/yolov8m.onnx\"\n",
    "\n",
    "def initialize(quantize=False, device='OVEP'):\n",
    "    \"Initialize the model also getting model output and input names\"\n",
    "    initialized = True\n",
    "    model_dir = os.getcwd()\n",
    "    ov_model = None; mlas_model = None\n",
    "    so = rt.SessionOptions()\n",
    "    if device == 'OVEP':\n",
    "        if quantize == True:\n",
    "            print(\"Inferencing through OVEP\")\n",
    "            ov_model = rt.InferenceSession(quantized_model_path, so,\n",
    "                                       providers=['OpenVINOExecutionProvider'],\n",
    "                                       provider_options=[{'device_type' : 'CPU_FP32'}])\n",
    "        else:\n",
    "            ov_model = rt.InferenceSession(original_model_path, so,\n",
    "                                       providers=['OpenVINOExecutionProvider'],\n",
    "                                        provider_options=[{'device_type' : 'CPU_FP32'}])\n",
    "    elif device == 'CPUEP':\n",
    "        if quantize == True:\n",
    "            mlas_model = rt.InferenceSession(quantized_model_path, so, providers=['CPUExecutionProvider'])\n",
    "        else:\n",
    "            mlas_model = rt.InferenceSession(original_model_path, so, providers=['CPUExecutionProvider'])\n",
    "\n",
    "    if device == 'OVEP':\n",
    "      input_names = ov_model.get_inputs()[0].name\n",
    "      outputs = ov_model.get_outputs()\n",
    "    else:\n",
    "      input_names = mlas_model.get_inputs()[0].name\n",
    "      outputs = mlas_model.get_outputs()\n",
    "    output_names = list(map(lambda output:output.name, outputs))\n",
    "    return input_names, output_names, mlas_model, ov_model\n",
    "\n",
    "device = 'OVEP'\n",
    "input_names, output_names, mlas_model, ov_model = initialize(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqI1dSmboO1r"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "h1tYkwGQnKtY"
   },
   "outputs": [],
   "source": [
    "#Select number of iterations for inference\n",
    "\n",
    "no_of_iterations = 20\n",
    "warmup_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bVFDmjaQoQhP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing ONNX Runtime Inference with OpenVINO EP.\n",
      "Average inference time is for 10 iterations is 0.022719 sec\n"
     ]
    }
   ],
   "source": [
    "inf_lst = []\n",
    "def inference(input_names, output_names, device, mlas_model, ovep_model, model_input):\n",
    "    if device == 'CPUEP':\n",
    "        print(\"Performing ONNX Runtime Inference with default CPU EP.\")\n",
    "        for i in range(no_of_iterations):\n",
    "          start_time = datetime.now()\n",
    "          prediction = mlas_model.run(output_names, {input_names: model_input})\n",
    "          end_time = datetime.now()\n",
    "          # print((end_time - start_time).total_seconds())\n",
    "          if i > warmup_iterations:\n",
    "            inf_lst.append((end_time - start_time).total_seconds())\n",
    "    elif device == 'OVEP':\n",
    "        print(\"Performing ONNX Runtime Inference with OpenVINO EP.\")\n",
    "        for i in range(no_of_iterations):\n",
    "          start_time = datetime.now()\n",
    "          prediction = ovep_model.run(output_names, {input_names: model_input})\n",
    "          end_time = datetime.now()\n",
    "          # print((end_time - start_time).total_seconds())\n",
    "          if i > warmup_iterations:\n",
    "            inf_lst.append((end_time - start_time).total_seconds())\n",
    "    else:\n",
    "        print(\"Invalid Device Option. Supported device options are 'cpu', 'CPU_FP32'.\")\n",
    "        return None\n",
    "    return prediction, (end_time - start_time).total_seconds()\n",
    "\n",
    "inference_output = inference(input_names, output_names, device, mlas_model, ov_model, model_input)\n",
    "average_inference_time = np.average(inf_lst)\n",
    "print(f'Average inference time is for {no_of_iterations - warmup_iterations} iterations is {average_inference_time} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1F3WqTCxA3v"
   },
   "source": [
    "## Final Inference on Webcam Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2fxUSilxC-I",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions import ai_gym\n",
    "import cv2\n",
    "\n",
    "model = YOLO(\"yolov8n.onnx\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "      print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "      break\n",
    "    frame_count += 1\n",
    "    results = model.predict(im0)  # Prediction also supported\n",
    "    res_plotted = results[0].plot()\n",
    "    cv2.imshow(\"Tracking_Stream\", res_plotted)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release() #Release video sources"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Q4cX8riJWuNk"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
